{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of nrlpq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghbhalerao/nrlpq/blob/main/NLRPQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xpS1yx2Xx2DW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f27cc6-6e35-46d1-f50d-6a429f542a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10"
      ],
      "metadata": {
        "id": "_xsmHEV2V405"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nesting_start=3\n",
        "\n",
        "class BlurPoolConv2d(torch.nn.Module):\n",
        "    def __init__(self, conv):\n",
        "        super().__init__()\n",
        "        default_filter = torch.tensor([[[[1, 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16.0\n",
        "        filt = default_filter.repeat(conv.in_channels, 1, 1, 1)\n",
        "        self.conv = conv\n",
        "        self.register_buffer('blur_filter', filt)\n",
        "\n",
        "    def forward(self, x):\n",
        "        blurred = F.conv2d(x, self.blur_filter, stride=1, padding=(1, 1),\n",
        "                           groups=self.conv.in_channels, bias=None)\n",
        "        return self.conv.forward(blurred)\n",
        "\n",
        "class Model():\n",
        "    def __init__(self, gpu, nesting, single_head, fixed_feature, use_blurpool):\n",
        "        super().__init__()\n",
        "        self.gpu = gpu\n",
        "        self.nesting = nesting\n",
        "        self.sh = single_head\n",
        "        self.ff = fixed_feature\n",
        "        self.use_blurpool = use_blurpool\n",
        "\n",
        "\n",
        "    def load_model(self, model, model_weights_disk, modify_keys = True):\n",
        "        if os.path.isfile(model_weights_disk):\n",
        "            print(\"=> loading checkpoint '{}'\".format(model_weights_disk))\n",
        "            if self.gpu is None:\n",
        "                checkpoint = torch.load(model_weights_disk)\n",
        "            else:\n",
        "                # Map model to be loaded to specified single gpu.\n",
        "                loc = 'cuda:{}'.format(self.gpu)\n",
        "                checkpoint = torch.load(model_weights_disk, map_location=loc)\n",
        "            if modify_keys:\n",
        "              checkpoint = self.change_str_dict(checkpoint)\n",
        "            \n",
        "\n",
        "\n",
        "            try:\n",
        "              model.load_state_dict(checkpoint)\n",
        "            except:\n",
        "              proxy_layer = nn.Linear(2048, num_classes)\n",
        "              print(\"randomly init last fc layer\")\n",
        "              checkpoint[\"fc.bias\"] = proxy_layer.bias\n",
        "              checkpoint[\"fc.weight\"] = proxy_layer.weight\n",
        "              print(checkpoint.keys())\n",
        "              model.load_state_dict(checkpoint)\n",
        "\n",
        "            print(\"=> loaded checkpoint '{}' \"\n",
        "                  .format(model_weights_disk))\n",
        "        else:\n",
        "            print(\"=> no model found at '{}'\".format(model_weights_disk))\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def change_str_dict(self, x):\n",
        "      x_ = {}\n",
        "      for key, val in x.items():\n",
        "        key_new = str(key).replace(\"module.\",\"\")\n",
        "        x_[key_new] = copy.copy(val)\n",
        "      return x_\n",
        "\n",
        "    def initModel(self):\n",
        "        print(\"Model init: nesting=%d, sh=%d, ff=%d\" %(self.nesting, self.sh, self.ff))\n",
        "        model = models.resnet50(pretrained=True)\n",
        "        nesting_list = [2**i for i in range(nesting_start, 12)] if self.nesting else None\n",
        "\n",
        "        # Nesting/Fixed Feature Modification code block\n",
        "        if self.nesting:\n",
        "            ff= \"Single Head\" if self.sh else \"Multi Head\"\n",
        "            print(\"Using Nesting of type - {}\".format(ff))\n",
        "            print(\"Nesting Starts from {}\".format(2**nesting_start))\n",
        "            if self.sh:\n",
        "                model.fc =  SingleHeadNestedLinear(nesting_list, num_classes=num_classes)\n",
        "            else:\n",
        "                model.fc =  MultiHeadNestedLinear(nesting_list, num_classes=num_classes)\n",
        "        elif self.ff != 2048:\n",
        "            print(f\"Using Fixed Features = {self.ff}\")\n",
        "            model.fc =  FixedFeatureLayer(self.ff, num_classes)\n",
        "\n",
        "        def apply_blurpool(mod: torch.nn.Module):\n",
        "            for (name, child) in mod.named_children():\n",
        "                if isinstance(child, torch.nn.Conv2d) and (np.max(child.stride) > 1 and child.in_channels >= 16):\n",
        "                    setattr(mod, name, BlurPoolConv2d(child))\n",
        "                else: apply_blurpool(child)\n",
        "        if self.use_blurpool: apply_blurpool(model)\n",
        "\n",
        "        model = model.to(memory_format=torch.channels_last)\n",
        "        model = model.to(self.gpu)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "\n",
        "class SingleHeadNestedLinear(nn.Linear):\n",
        "\tdef __init__(self, nesting_list: List, num_classes=num_classes, **kwargs):\n",
        "\t\tsuper(SingleHeadNestedLinear, self).__init__(nesting_list[-1], num_classes, **kwargs)\n",
        "\t\tself.nesting_list=nesting_list\n",
        "\t\tself.num_classes=num_classes # Number of classes for classification\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tnesting_logits = ()\n",
        "\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
        "\t\t\tif not (self.bias is None):\n",
        "\t\t\t\tlogit = torch.matmul(x[:, :num_feat], (self.weight[:, :num_feat]).t()) + self.bias\n",
        "\t\t\telse:\n",
        "\t\t\t\tlogit = torch.matmul(x[:, :num_feat], (self.weight[:, :num_feat]).t())\n",
        "\t\t\tnesting_logits+= (logit,)\n",
        "\t\treturn nesting_logits\n",
        "\n",
        "class MultiHeadNestedLinear(nn.Module):\n",
        "\tdef __init__(self, nesting_list: List, num_classes=num_classes, **kwargs):\n",
        "\t\tsuper(MultiHeadNestedLinear, self).__init__()\n",
        "\t\tself.nesting_list=nesting_list\n",
        "\t\tself.num_classes=num_classes # Number of classes for classification\n",
        "\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
        "\t\t\tsetattr(self, f\"nesting_classifier_{i}\", nn.Linear(num_feat, self.num_classes, **kwargs))\t\t\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tnesting_logits = ()\n",
        "\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
        "\t\t\tnesting_logits +=  (getattr(self, f\"nesting_classifier_{i}\")(x[:, :num_feat]),)\n",
        "\t\treturn nesting_logits\n",
        "\n",
        "\t\t\n",
        "class FixedFeatureLayer(nn.Linear):\n",
        "    # This layer just takes the first \"K\" Features for the classification. \n",
        "    # Creating a separate layer and customized fwd pass helps to not change the base codes at all.\n",
        "    def __init__(self, in_features, out_features, **kwargs):\n",
        "        super(FixedFeatureLayer, self).__init__(in_features, out_features, **kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not (self.bias is None):\n",
        "            out = torch.matmul(x[:, :self.in_features], self.weight.t()) + self.bias\n",
        "        else:\n",
        "            out = torch.matmul(x[:, :self.in_features], self.weight.t())\n",
        "        return out\n",
        "\n",
        "class NestedCELoss(nn.Module):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(NestedCELoss, self).__init__()\n",
        "\t\tself.criterion = nn.CrossEntropyLoss(**kwargs)\n",
        "\tdef forward(self, output, target):\n",
        "\t\tloss=0\n",
        "\t\tfor o in output:\n",
        "\t\t\tloss+= self.criterion(o, target)\n",
        "\n",
        "\t\treturn loss"
      ],
      "metadata": {
        "id": "5GlfwMHQ4Voy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device):\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        # training\n",
        "        print(f'EPOCH:{epoch}')\n",
        "        print('Computing Train Loss..')\n",
        "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
        "      \n",
        "        print(train_loss)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            print('Computing Validation Loss..')\n",
        "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
        "            print(valid_loss)\n",
        "            valid_losses.append(valid_loss)\n",
        "        print('--------------------------------')\n",
        "  \n",
        "    return model, train_losses, valid_losses\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X) \n",
        "        loss = criterion(pred, y) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      #  print(loss.cpu().data.item())\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss\n",
        "\n",
        "def validate(valid_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct_count, all_count = 0, 0\n",
        "    \n",
        "    for X, y in valid_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X) \n",
        "        \n",
        "        loss = criterion(pred, y) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
        "    return model, epoch_loss\n",
        "\n",
        "def get_accuracy(model,data_loader,rep_no, device):\n",
        "  correct_count, all_count = 0, 0\n",
        "  for images,labels in data_loader:\n",
        "    images,labels = images.to(device), labels.to(device)\n",
        "    images = images.to(device)\n",
        "    true_label = labels.to(device)\n",
        "    pred = model(images) \n",
        "    pred = pred[rep_no]\n",
        "    pred_label = torch.argmax(pred, dim=1)\n",
        "    correct_count += torch.eq(true_label, pred_label).sum().item()\n",
        "    all_count +=len(true_label)\n",
        "  return correct_count/all_count\n",
        "    "
      ],
      "metadata": {
        "id": "5Sv9k7-7p5DG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mdl_wts = os.path.join(\"/content/gdrive/MyDrive/nrlpq/Imagenet1k_R50_sh1_mh0_ns3_ff2048/final_weights.pt\")\n",
        "model_wts_path = os.path.join(mdl_wts)\n",
        "nesting = 1\n",
        "single_head = 1\n",
        "fixed_feature = 2048\n",
        "model = Model(0, nesting, single_head, fixed_feature, use_blurpool=1)\n",
        "\n",
        "\n",
        "model_init = model.initModel()\n",
        "model = model.load_model(model_init, model_wts_path)\n",
        "print(\"Loaded pretrained model: \" + str(model_wts_path))\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "print(\"batch size is\", batch_size)\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset_all = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "n_alltrain = len(trainset_all)\n",
        "print(\"len of all train data is\", n_alltrain)\n",
        "\n",
        "n_train = int(n_alltrain * 0.8)\n",
        "n_val = n_alltrain - n_train\n",
        "print(\"len of train val split is \", n_train, n_val, \"respectively\")\n",
        "\n",
        "val_idxs = np.random.choice(n_alltrain, size = n_val ,replace=False)\n",
        "\n",
        "trainset = Subset(trainset_all, list(set(range(len(trainset_all))) -  set(val_idxs)))\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "valset = Subset(trainset_all, val_idxs)\n",
        "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(\"length of train, val and test DataLoader is \", len(train_loader), len(val_loader), len(test_loader))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = NestedCELoss()\n",
        "epochs = 1\n",
        "device = torch.device('cuda')\n",
        "model,_,_ = training_loop(model, criterion, optimizer, train_loader, val_loader, epochs, device)\n",
        "res = get_accuracy(model, test_loader,3, device)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdwXgxeQ_DNI",
        "outputId": "2f63110d-4cbb-4e87-a59f-df0ae595bd04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model init: nesting=1, sh=1, ff=2048\n",
            "Using Nesting of type - Single Head\n",
            "Nesting Starts from 8\n",
            "=> no model found at '/content/gdrive/MyDrive/nrlpq/Imagenet1k_R50_sh1_mh0_ns3_ff2048/final_weights.pt'\n",
            "Loaded pretrained model: /content/gdrive/MyDrive/nrlpq/Imagenet1k_R50_sh1_mh0_ns3_ff2048/final_weights.pt\n",
            "batch size is 128\n",
            "Files already downloaded and verified\n",
            "len of all train data is 50000\n",
            "len of train val split is  40000 10000 respectively\n",
            "Files already downloaded and verified\n",
            "length of train, val and test DataLoader is  313 79 79\n",
            "EPOCH:0\n",
            "Computing Train Loss..\n",
            "9.938902421569825\n",
            "Computing Validation Loss..\n",
            "7.365488230895996\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6J9wr83_KMW",
        "outputId": "b6837425-46a7-411e-f569-d65cf43afaf5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): BlurPoolConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): BlurPoolConv2d(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): BlurPoolConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): BlurPoolConv2d(\n",
              "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): BlurPoolConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): BlurPoolConv2d(\n",
              "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): SingleHeadNestedLinear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_dict = {'layer1':[[\"conv1\", \"bn1\"], [\"conv2\", \"bn2\"], [\"conv3\", \"bn3\", 'relu'] ]}"
      ],
      "metadata": {
        "id": "TxL-SHZ3_oUj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuse the model in place rather manually.\n",
        "model.to(device)\n",
        "# Make a copy of the model for layer fusion\n",
        "fused_model = copy.deepcopy(model)\n",
        "\n",
        "model.eval()\n",
        "# The model has to be switched to evaluation mode before any layer fusion.\n",
        "# Otherwise the quantization will not work correctly.\n",
        "fused_model.eval()\n",
        "\n",
        "fused_model = torch.quantization.fuse_modules(fused_model, [[\"conv1\", \"bn1\", \"relu\"]], inplace=True)\n",
        "for module_name, module in fused_model.named_children():\n",
        "    if \"layer\" in module_name:\n",
        "        for basic_block_name, basic_block in module.named_children():\n",
        "            torch.quantization.fuse_modules(basic_block, layer_dict[module_name], inplace=True)\n",
        "            for sub_block_name, sub_block in basic_block.named_children():\n",
        "                if sub_block_name == \"downsample\":\n",
        "                    torch.quantization.fuse_modules(sub_block, [[\"0\", \"1\"]], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "4mI4g4cT_hQj",
        "outputId": "5f6bd693-841c-4e29-e81f-ca1412c22a5b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-67d7beeda1f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"layer\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbasic_block_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasic_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msub_block_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbasic_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msub_block_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"downsample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'layer2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fused_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTseDMmn_lK7",
        "outputId": "2477aa9e-bcf8-4a78-fa66-ca1abf7e8ba6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): ConvReLU2d(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): ConvReLU2d(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn3): Identity()\n",
              "      (relu): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): ConvReLU2d(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn3): Identity()\n",
              "      (relu): Identity()\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): ConvReLU2d(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn3): Identity()\n",
              "      (relu): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): BlurPoolConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): BlurPoolConv2d(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): BlurPoolConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): BlurPoolConv2d(\n",
              "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): BlurPoolConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): BlurPoolConv2d(\n",
              "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): SingleHeadNestedLinear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "flzMO172BEj5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}