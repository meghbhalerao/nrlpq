{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of nrlpq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghbhalerao/nrlpq/blob/main/Copy_of_nrlpq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xpS1yx2Xx2DW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0766346f-6bbb-41f3-8ddb-c11a503ba35a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10"
      ],
      "metadata": {
        "id": "_xsmHEV2V405"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nesting_start=3\n",
        "\n",
        "class BlurPoolConv2d(torch.nn.Module):\n",
        "    def __init__(self, conv):\n",
        "        super().__init__()\n",
        "        default_filter = torch.tensor([[[[1, 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16.0\n",
        "        filt = default_filter.repeat(conv.in_channels, 1, 1, 1)\n",
        "        self.conv = conv\n",
        "        self.register_buffer('blur_filter', filt)\n",
        "\n",
        "    def forward(self, x):\n",
        "        blurred = F.conv2d(x, self.blur_filter, stride=1, padding=(1, 1),\n",
        "                           groups=self.conv.in_channels, bias=None)\n",
        "        return self.conv.forward(blurred)\n",
        "\n",
        "class Model():\n",
        "    def __init__(self, gpu, nesting, single_head, fixed_feature, use_blurpool):\n",
        "        super().__init__()\n",
        "        self.gpu = gpu\n",
        "        self.nesting = nesting\n",
        "        self.sh = single_head\n",
        "        self.ff = fixed_feature\n",
        "        self.use_blurpool = use_blurpool\n",
        "\n",
        "\n",
        "    def load_model(self, model, model_weights_disk, modify_keys = True):\n",
        "        if os.path.isfile(model_weights_disk):\n",
        "            print(\"=> loading checkpoint '{}'\".format(model_weights_disk))\n",
        "            if self.gpu is None:\n",
        "                checkpoint = torch.load(model_weights_disk)\n",
        "            else:\n",
        "                # Map model to be loaded to specified single gpu.\n",
        "                loc = 'cuda:{}'.format(self.gpu)\n",
        "                checkpoint = torch.load(model_weights_disk, map_location=loc)\n",
        "            if modify_keys:\n",
        "              checkpoint = self.change_str_dict(checkpoint)\n",
        "            \n",
        "\n",
        "\n",
        "            try:\n",
        "              model.load_state_dict(checkpoint)\n",
        "            except:\n",
        "              proxy_layer = nn.Linear(2048, num_classes)\n",
        "              print(\"randomly init last fc layer\")\n",
        "              checkpoint[\"fc.bias\"] = proxy_layer.bias\n",
        "              checkpoint[\"fc.weight\"] = proxy_layer.weight\n",
        "              print(checkpoint.keys())\n",
        "              model.load_state_dict(checkpoint)\n",
        "\n",
        "            print(\"=> loaded checkpoint '{}' \"\n",
        "                  .format(model_weights_disk))\n",
        "        else:\n",
        "            print(\"=> no model found at '{}'\".format(model_weights_disk))\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def change_str_dict(self, x):\n",
        "      x_ = {}\n",
        "      for key, val in x.items():\n",
        "        key_new = str(key).replace(\"module.\",\"\")\n",
        "        x_[key_new] = copy.copy(val)\n",
        "      return x_\n",
        "\n",
        "    def initModel(self):\n",
        "        print(\"Model init: nesting=%d, sh=%d, ff=%d\" %(self.nesting, self.sh, self.ff))\n",
        "        model = models.resnet50(pretrained=True)\n",
        "        nesting_list = [2**i for i in range(nesting_start, 12)] if self.nesting else None\n",
        "\n",
        "        # Nesting/Fixed Feature Modification code block\n",
        "        if self.nesting:\n",
        "            ff= \"Single Head\" if self.sh else \"Multi Head\"\n",
        "            print(\"Using Nesting of type - {}\".format(ff))\n",
        "            print(\"Nesting Starts from {}\".format(2**nesting_start))\n",
        "            if self.sh:\n",
        "                model.fc =  SingleHeadNestedLinear(nesting_list, num_classes=num_classes)\n",
        "            else:\n",
        "                model.fc =  MultiHeadNestedLinear(nesting_list, num_classes=num_classes)\n",
        "        elif self.ff != 2048:\n",
        "            print(f\"Using Fixed Features = {self.ff}\")\n",
        "            model.fc =  FixedFeatureLayer(self.ff, num_classes)\n",
        "\n",
        "        def apply_blurpool(mod: torch.nn.Module):\n",
        "            for (name, child) in mod.named_children():\n",
        "                if isinstance(child, torch.nn.Conv2d) and (np.max(child.stride) > 1 and child.in_channels >= 16):\n",
        "                    setattr(mod, name, BlurPoolConv2d(child))\n",
        "                else: apply_blurpool(child)\n",
        "        if self.use_blurpool: apply_blurpool(model)\n",
        "\n",
        "        model = model.to(memory_format=torch.channels_last)\n",
        "        model = model.to(self.gpu)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "\n",
        "class SingleHeadNestedLinear(nn.Linear):\n",
        "\tdef __init__(self, nesting_list: List, num_classes=num_classes, **kwargs):\n",
        "\t\tsuper(SingleHeadNestedLinear, self).__init__(nesting_list[-1], num_classes, **kwargs)\n",
        "\t\tself.nesting_list=nesting_list\n",
        "\t\tself.num_classes=num_classes # Number of classes for classification\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tnesting_logits = ()\n",
        "\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
        "\t\t\tif not (self.bias is None):\n",
        "\t\t\t\tlogit = torch.matmul(x[:, :num_feat], (self.weight[:, :num_feat]).t()) + self.bias\n",
        "\t\t\telse:\n",
        "\t\t\t\tlogit = torch.matmul(x[:, :num_feat], (self.weight[:, :num_feat]).t())\n",
        "\t\t\tnesting_logits+= (logit,)\n",
        "\t\treturn nesting_logits\n",
        "\n",
        "class MultiHeadNestedLinear(nn.Module):\n",
        "\tdef __init__(self, nesting_list: List, num_classes=num_classes, **kwargs):\n",
        "\t\tsuper(MultiHeadNestedLinear, self).__init__()\n",
        "\t\tself.nesting_list=nesting_list\n",
        "\t\tself.num_classes=num_classes # Number of classes for classification\n",
        "\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
        "\t\t\tsetattr(self, f\"nesting_classifier_{i}\", nn.Linear(num_feat, self.num_classes, **kwargs))\t\t\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tnesting_logits = ()\n",
        "\t\tfor i, num_feat in enumerate(self.nesting_list):\n",
        "\t\t\tnesting_logits +=  (getattr(self, f\"nesting_classifier_{i}\")(x[:, :num_feat]),)\n",
        "\t\treturn nesting_logits\n",
        "\n",
        "\t\t\n",
        "class FixedFeatureLayer(nn.Linear):\n",
        "    # This layer just takes the first \"K\" Features for the classification. \n",
        "    # Creating a separate layer and customized fwd pass helps to not change the base codes at all.\n",
        "    def __init__(self, in_features, out_features, **kwargs):\n",
        "        super(FixedFeatureLayer, self).__init__(in_features, out_features, **kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not (self.bias is None):\n",
        "            out = torch.matmul(x[:, :self.in_features], self.weight.t()) + self.bias\n",
        "        else:\n",
        "            out = torch.matmul(x[:, :self.in_features], self.weight.t())\n",
        "        return out\n",
        "\n",
        "class NestedCELoss(nn.Module):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(NestedCELoss, self).__init__()\n",
        "\t\tself.criterion = nn.CrossEntropyLoss(**kwargs)\n",
        "\tdef forward(self, output, target):\n",
        "\t\tloss=0\n",
        "\t\tfor o in output:\n",
        "\t\t\tloss+= self.criterion(o, target)\n",
        "\n",
        "\t\treturn loss"
      ],
      "metadata": {
        "id": "5GlfwMHQ4Voy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "mdl_wts = os.path.join(\"/content/gdrive/MyDrive/nrlpq/Imagenet1k_R50_sh1_mh0_ns3_ff2048/final_weights.pt\")\n",
        "model_wts_path = os.path.join(mdl_wts)\n",
        "nesting = 1\n",
        "single_head = 1\n",
        "fixed_feature = 2048\n",
        "model = Model(0, nesting, single_head, fixed_feature, use_blurpool=1)\n",
        "\n",
        "\n",
        "model_init = model.initModel()\n",
        "model = model.load_model(model_init, model_wts_path)\n",
        "print(\"Loaded pretrained model: \" + str(model_wts_path))\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "print(\"batch size is\", batch_size)\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset_all = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "n_alltrain = len(trainset_all)\n",
        "print(\"len of all train data is\", n_alltrain)\n",
        "\n",
        "n_train = int(n_alltrain * 0.8)\n",
        "n_val = n_alltrain - n_train\n",
        "print(\"len of train val split is \", n_train, n_val, \"respectively\")\n",
        "\n",
        "val_idxs = np.random.choice(n_alltrain, size = n_val ,replace=False)\n",
        "\n",
        "trainset = Subset(trainset_all, list(set(range(len(trainset_all))) -  set(val_idxs)))\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "valset = Subset(trainset_all, val_idxs)\n",
        "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(\"length of train, val and test DataLoader is \", len(train_loader), len(val_loader), len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24WPtHjGy1vD",
        "outputId": "503a0ee4-aa2a-4863-944d-e2d006e1c8b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model init: nesting=1, sh=1, ff=2048\n",
            "Using Nesting of type - Single Head\n",
            "Nesting Starts from 8\n",
            "=> loading checkpoint '/content/gdrive/MyDrive/nrlpq/Imagenet1k_R50_sh1_mh0_ns3_ff2048/final_weights.pt'\n",
            "randomly init last fc layer\n",
            "dict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.blur_filter', 'layer2.0.conv2.conv.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.blur_filter', 'layer2.0.downsample.0.conv.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.blur_filter', 'layer3.0.conv2.conv.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.blur_filter', 'layer3.0.downsample.0.conv.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.blur_filter', 'layer4.0.conv2.conv.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.blur_filter', 'layer4.0.downsample.0.conv.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])\n",
            "=> loaded checkpoint '/content/gdrive/MyDrive/nrlpq/Imagenet1k_R50_sh1_mh0_ns3_ff2048/final_weights.pt' \n",
            "Loaded pretrained model: /content/gdrive/MyDrive/nrlpq/Imagenet1k_R50_sh1_mh0_ns3_ff2048/final_weights.pt\n",
            "batch size is 128\n",
            "Files already downloaded and verified\n",
            "len of all train data is 50000\n",
            "len of train val split is  40000 10000 respectively\n",
            "Files already downloaded and verified\n",
            "length of train, val and test DataLoader is  313 79 79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device):\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        # training\n",
        "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
        "            valid_losses.append(valid_loss)\n",
        "        print(f'EPOCH:{epoch}')\n",
        "  \n",
        "    return model, train_losses, valid_losses\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X) \n",
        "        for t in pred:\n",
        "          print(t.shape)\n",
        "        loss = criterion(pred, y) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss.cpu().data.item())\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss\n",
        "\n",
        "def validate(valid_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct_count, all_count = 0, 0\n",
        "    \n",
        "    for X, y in valid_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X) \n",
        "        \n",
        "        loss = criterion(pred, y) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
        "    return model, epoch_loss\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "  correct_count, all_count = 0, 0\n",
        "  pred_prob = 0\n",
        "  i=0\n",
        "  first_batch = None\n",
        "  init_pred_label = None\n",
        "  for images,labels in data_loader:\n",
        "    images,labels = images.to(device), labels.to(device)\n",
        "    with torch.no_grad():\n",
        "        logps = model(images)\n",
        "    ps = F.softmax(logps, dim=1)\n",
        "    if device!='cpu':\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      pred_label = ps.argmax(axis=1)\n",
        "      if i==0:\n",
        "        pred_prob = ps.max(axis=1)\n",
        "        init_pred_label = pred_label\n",
        "        first_batch = (images, labels)\n",
        "        i+=1\n",
        "      true_label = labels\n",
        "    else:\n",
        "      probab = list(ps.numpy()[0])\n",
        "      pred_label = ps.argmax(axis=1)\n",
        "      if i==0:\n",
        "        pred_prob = ps.max(axis=1)\n",
        "        init_pred_label = pred_label\n",
        "        first_batch = (images, labels)\n",
        "        i+=1\n",
        "      true_label = labels\n",
        "    correct_count += torch.eq(true_label, pred_label).sum().item()\n",
        "    all_count += len(true_label)\n",
        "  return correct_count/all_count, [i.item() for i in list(pred_prob[0])[:10]], init_pred_label, first_batch\n",
        "\n",
        "def get_accuracy(model,data_loader):\n",
        "  correct_count, all_count = 0, 0\n",
        "  for images,labels in data_loader:\n",
        "    images,labels = images.to(device), labels.to(device)\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = model(images) \n",
        "    "
      ],
      "metadata": {
        "id": "D3JMQx2y2jJL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = NestedCELoss()\n",
        "epochs = 2\n",
        "device = torch.device('cuda')\n",
        "training_loop(model, criterion, optimizer, train_loader, val_loader, epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5xyRlzQQqXBv",
        "outputId": "eb905c76-bf97-4b86-e72a-79463babdc7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.39367151260376\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.052010536193848\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "8.242942810058594\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.567515850067139\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.0755157470703125\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.803653240203857\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.999931812286377\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.635767459869385\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.608877658843994\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.649118900299072\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.086980819702148\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.948212623596191\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.339018821716309\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.828948497772217\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.960110664367676\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.702817440032959\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.52442741394043\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.9546380043029785\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.7840375900268555\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.062481880187988\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.116827964782715\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.004063129425049\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.515537261962891\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.8669586181640625\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.750199317932129\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.843684196472168\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.88604736328125\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.225239276885986\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.048981666564941\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.137066841125488\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.300208568572998\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.97532320022583\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.321218013763428\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.176506042480469\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.959103107452393\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.138440132141113\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.405472755432129\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.827957630157471\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.645449638366699\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.186131954193115\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.968940734863281\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.636277675628662\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.769261360168457\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.4269328117370605\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.89053201675415\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.432227611541748\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.69685697555542\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.9749979972839355\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.943413257598877\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.740215301513672\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "8.782658576965332\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.349420070648193\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.20823860168457\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.000580787658691\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.022199630737305\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.222149848937988\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.49975061416626\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.004062175750732\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.919196605682373\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.023475646972656\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.936498165130615\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.47373104095459\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.865419864654541\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.318697929382324\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.35312032699585\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "8.311068534851074\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "8.022122383117676\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.55642032623291\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.807662010192871\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.522531509399414\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.96439790725708\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.5461812019348145\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.683273792266846\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.890604019165039\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.171080112457275\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.263907432556152\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.230419635772705\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.198938369750977\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.675921440124512\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.1569743156433105\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.427238464355469\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.564517974853516\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.848199367523193\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.347062587738037\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.686568737030029\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "8.028400421142578\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.546507835388184\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.894543647766113\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.9387664794921875\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.15531063079834\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.1284637451171875\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.41684627532959\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.5002827644348145\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.000982761383057\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.40003776550293\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.857089519500732\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.185867786407471\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.885439872741699\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.6135573387146\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.749399662017822\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.255251407623291\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.0873894691467285\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.022433280944824\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.797300815582275\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.964916706085205\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.816474914550781\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.727965831756592\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.922801494598389\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.560573577880859\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.300387859344482\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.390949249267578\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.680291175842285\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.746413707733154\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.428332328796387\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.309510707855225\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.479582786560059\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "8.263202667236328\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.044310569763184\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.359745025634766\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.590775489807129\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.599179267883301\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.003362655639648\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.180432319641113\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.022550106048584\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.276091575622559\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.063754558563232\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.559414863586426\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.35584020614624\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.192927360534668\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.592379093170166\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "7.797192573547363\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.987403869628906\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.631343841552734\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.719305992126465\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.4014739990234375\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.626626968383789\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.808494567871094\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.847588539123535\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "6.102721214294434\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "4.815286636352539\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "5.896125793457031\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n",
            "torch.Size([128, 10])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1b0671054a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-8c2e42890c84>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, epochs, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8c2e42890c84>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = get_accuracy(model, val_loader)\n",
        "res[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YKC-S-3uqi_J",
        "outputId": "4d6ad61c-ddf7-4afa-b3c2-01d5363f439c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([128, 1000])\n",
            "torch.Size([16, 1000])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e2e7135ceed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "paaQSIdJtPoX",
        "outputId": "224c4573-2c20-4c0f-ee49-ef9582237184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1186\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " for images,labels in test_loader:\n",
        "   print(images.shape)\n",
        "   print(labels)\n",
        "   print(F.one_hot(labels))\n",
        "   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_t3Bvkk0Qio",
        "outputId": "eb21f8a8-c544-4781-8892-edc85aa98d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0, 6, 2, 1, 3, 0, 4, 2, 7,\n",
            "        8, 3, 1, 2, 8, 0, 8, 3])\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0],\n",
            "        ...,\n",
            "        [1, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eAGmwBbp0dYe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}